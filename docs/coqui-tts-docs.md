# ðŸ¸ Coqui TTS Documentation

## VisÃ£o Geral

**ðŸ¸TTS Ã© uma biblioteca para geraÃ§Ã£o avanÃ§ada de Text-to-Speech.**

- ðŸš€ Modelos prÃ©-treinados em +1100 idiomas
- ðŸ› ï¸ Ferramentas para treinar novos modelos
- ðŸ“š UtilitÃ¡rios para anÃ¡lise e curadoria de datasets

## InstalaÃ§Ã£o

### Requisitos
- Python >= 3.9, < 3.12
- Ubuntu 18.04+

### InstalaÃ§Ã£o via pip (recomendado)
```bash
pip install TTS
```

### InstalaÃ§Ã£o via git
```bash
git clone https://github.com/coqui-ai/TTS
pip install -e .[all,dev,notebooks]
```

## Uso BÃ¡sico - Python API

### ImportaÃ§Ã£o
```python
from TTS.api import TTS
```

### Sintetizar Fala

```python
# Inicializar TTS
tts = TTS("tts_models/pt/cv/vits")

# Gerar Ã¡udio
tts.tts_to_file(
    "Este Ã© um teste de sintetizaÃ§Ã£o de fala em portuguÃªs.",
    file_path="output.wav"
)
```

## Modelos DisponÃ­veis

### Listar Modelos
```python
from TTS.api import TTS

# Listar todos os modelos
models = TTS.list_models()

# Buscar modelos por idioma
portuguese_models = [m for m in models if 'pt' in m.lower()]
```

### Modelos Comuns

**PortuguÃªs:**
- `tts_models/pt/cv/vits` - PortuguÃªs (Common Voice)
- `tts_models/multilingual/multi-dataset/xtts_v2` - MultilÃ­ngue com clonagem de voz

**MultilÃ­ngue:**
- `tts_models/multilingual/multi-dataset/xtts_v2` - Clonagem de voz com 16 idiomas
- `tts_models/multilingual/multi-dataset/your_tts` - MultilÃ­ngue avanÃ§ado

## Clonagem de Voz (Voice Cloning)

```python
from TTS.api import TTS

# Inicializar XTTS (suporta clonagem)
tts = TTS("tts_models/multilingual/multi-dataset/xtts_v2")

# Clonar voz
tts.tts_to_file(
    text="OlÃ¡, esta Ã© uma mensagem de teste.",
    speaker_wav="ref_speaker.wav",  # Arquivo de referÃªncia
    language="pt",
    file_path="output.wav"
)
```

## API Completa do TTS

### InicializaÃ§Ã£o
```python
TTS(
    model_name: str,           # Nome do modelo
    gpu: bool = False,         # Usar GPU
    progress_bar: bool = True  # Mostrar barra de progresso
)
```

### MÃ©todos Principais

#### `tts_to_file()`
Sintetizar fala e salvar em arquivo.

```python
tts.tts_to_file(
    text: str,                    # Texto a ser sintetizado
    file_path: str,               # Caminho do arquivo de saÃ­da
    speaker_wav: str = None,      # Arquivo de voz de referÃªncia (clonagem)
    language: str = None,          # Idioma (para XTTS)
    **kwargs                      # Outros parÃ¢metros especÃ­ficos do modelo
)
```

#### `tts()`
Sintetizar fala e retornar array NumPy.

```python
wav = tts.tts(
    text="OlÃ¡, mundo!",
    speaker_wav="speaker.wav"
)
```

#### `speaker_manager`
Gerenciar speakers (vozes)

```python
# Listar speakers disponÃ­veis
speakers = tts.speaker_manager.speakers

# Usar speaker especÃ­fico
tts.tts_to_file(
    text="OlÃ¡",
    file_path="output.wav",
    speaker=speakers[0]  # ou speaker_name
)
```

## ParÃ¢metros Comuns

### Velocidade
```python
tts.tts_to_file(
    text="Texto",
    file_path="output.wav",
    speed=1.2  # Mais rÃ¡pido (padrÃ£o: 1.0)
)
```

### Temperature (XTTS)
```python
tts.tts_to_file(
    text="Texto",
    file_path="output.wav",
    speaker_wav="speaker.wav",
    temperature=0.7  # Controle criatividade (0.0-1.0)
)
```

### Top-p e Top-k (XTTS)
```python
tts.tts_to_file(
    text="Texto",
    file_path="output.wav",
    speaker_wav="speaker.wav",
    top_p=0.85,  # Nucleus sampling
    top_k=50     # Top-k sampling
)
```

## Streaming (Baixa LatÃªncia)

```python
from TTS.api import TTS
import numpy as np

# Inicializar com streaming
tts = TTS("tts_models/multilingual/multi-dataset/xtts_v2")

# Gerar com streaming (< 200ms latÃªncia)
for wav_chunk in tts.tts_stream(
    text="Este Ã© um texto longo que serÃ¡ processado em chunks.",
    stream_chunk_size=100,  # Tamanho do chunk
    speaker_wav="speaker.wav",
    language="pt"
):
    # Processar chunks incrementalmente
    print(f"Chunk: {len(wav_chunk)} samples")
```

## Modelos Especializados

### Bark (Generation de Sons)
```python
from TTS.api import TTS

tts = TTS("tts_models/en/ljspeech/bark")
tts.tts_to_file(
    text="Can you generate: meow [LAUGHS], bark bark",
    file_path="output.wav"
)
```

### Tortoise (Alta Qualidade)
```python
tts = TTS("tts_models/en/ljspeech/tortoise-v2")
tts.tts_to_file(
    text="Texto com qualidade muito alta",
    file_path="output.wav",
    voice_samples=["voice1.wav", "voice2.wav", "voice3.wav"],
    conditioning_latents=None,
    k=1,
    use_deterministic_seed=42
)
```

## Suporte a MÃºltiplos Idiomas

### XTTS v2 (16 Idiomas)
```python
tts = TTS("tts_models/multilingual/multi-dataset/xtts_v2")

# PortuguÃªs
tts.tts_to_file("OlÃ¡", file_path="pt.wav", language="pt")

# InglÃªs
tts.tts_to_file("Hello", file_path="en.wav", language="en")

# Espanhol
tts.tts_to_file("Hola", file_path="es.wav", language="es")

# AlemÃ£o
tts.tts_to_file("Hallo", file_path="de.wav", language="de")
```

**Idiomas suportados pelo XTTS v2:**
- en, es, fr, de, it, pt, pl, tr, ru, nl, cs, ar, zh-cn, ja, hu, ko

## Command Line (tts)

### Sintaxe BÃ¡sica
```bash
tts --text "Texto" --out_path output.wav
```

### Com Modelo EspecÃ­fico
```bash
tts --text "Texto" \
    --model_name "tts_models/pt/cv/vits" \
    --out_path output.wav
```

### Com Speaker
```bash
tts --text "Texto" \
    --out_path output.wav \
    --model_name "modelo_multispeaker" \
    --speaker_idx 0
```

### Stream Output
```bash
tts --text "Texto" \
    --out_path output.wav \
    --pipe_out | aplay
```

## Troubleshooting

### Modelo nÃ£o encontrado
```python
# Listar modelos disponÃ­veis
from TTS.api import TTS
print(TTS.list_models())
```

### Erro de memÃ³ria
```python
# Usar CPU ao invÃ©s de GPU
tts = TTS("modelo", gpu=False)

# Ou usar GPU especÃ­fica
import os
os.environ["CUDA_VISIBLE_DEVICES"] = "0"
```

### Clonagem nÃ£o funciona
- Certifique-se de usar XTTS ou YourTTS
- Audio de referÃªncia deve ter pelo menos 3 segundos
- Formato: WAV, 22050 Hz ou 24000 Hz

## Recursos Adicionais

- **GitHub:** https://github.com/coqui-ai/TTS
- **DocumentaÃ§Ã£o:** https://docs.coqui.ai/
- **Discord:** https://discord.gg/5eXr5seRrv
- **Coqui Studio:** https://coqui.ai/studio
- **Blog:** https://coqui.ai/blog

## Exemplos de IntegraÃ§Ã£o

### Com FastAPI
```python
from fastapi import FastAPI
from TTS.api import TTS

app = FastAPI()
tts = TTS("tts_models/multilingual/multi-dataset/xtts_v2")

@app.post("/synthesize")
def synthesize(text: str, speaker_wav: str):
    tts.tts_to_file(
        text=text,
        speaker_wav=speaker_wav,
        file_path="output.wav",
        language="pt"
    )
    return {"status": "success", "file": "output.wav"}
```

### Com Streamlit
```python
import streamlit as st
from TTS.api import TTS

tts = TTS("tts_models/pt/cv/vits")

text = st.text_input("Digite o texto:")
if st.button("Sintetizar"):
    tts.tts_to_file(text, file_path="output.wav")
    st.audio("output.wav")
```

## LicenÃ§a

A maioria dos modelos usa a licenÃ§a MPL 2.0.

---
*DocumentaÃ§Ã£o gerada a partir de https://docs.coqui.ai/*

